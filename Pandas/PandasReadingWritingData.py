We will be seeing I/O APIs (a set of function) available with pandas library. These functions are divided into 2 categories ::

Readers ::            
read_csv                            
read_excel
read_hdf
read_sql
read_json
read_html
read_stata
read_clipboard
read_pickle
read_msgpack
read_gbq

Writers ::
to_csv
to_excel
to_hdf
to_sql
to_json
to_html
to_stata
to_clipboard to_pickle
to_msgpack (experimental) to_gbq (experimental)

>>> import os
>>> os.chdir('/Users/sankar.biswas/Desktop/AI:ML docs/Notebooks/InputFiles')

>>> csvFrame = pd.read_csv('input.txt')
>>> csvFrame
   white  red  blue  green animal
0      1    5     2      3    cat
1      2    7     8      5    dog
2      3    3     6      7  horse
3      2    2     8      3   duck
4      4    4     2      1  mouse

If you want to use separator for your input file ::

>>> csvFrame = pd.read_table('input.txt', sep = ',')
>>> csvFrame
   white  red  blue  green animal
0      1    5     2      3    cat
1      2    7     8      5    dog
2      3    3     6      7  horse
3      2    2     8      3   duck
4      4    4     2      1  mouse

# generally first line of the input file is considered as the header, but if you would like to not do that, you would have to 
# specify that, so by default column names will be specified

>>> csvFrame = pd.read_csv('input.txt', header= None)
>>> csvFrame
       0    1     2      3       4
0  white  red  blue  green  animal
1      1    5     2      3     cat
2      2    7     8      5     dog
3      3    3     6      7   horse
4      2    2     8      3    duck
5      4    4     2      1   mouse

# or you can give your own headers while importing the dataset (removing the header from the input file)
>>> csvFrame = pd.read_csv('input.txt', names = ['white','red','blue','green','animal'])
>>> csvFrame
   white  red  blue  green animal
0      1    5     2      3    cat
1      2    7     8      5    dog
2      3    3     6      7  horse
3      2    2     8      3   duck
4      4    4     2      1  mouse

# Hierarchical structure in index 
input data :: 
color,status,item1,item2,item3
black,up,3,4,6
black,down,2,6,7
white,up,5,5,5
white,down,3,3,2
white,left,1,2,1
red,up,2,2,2
red,down,1,1,4


>>> csvFrame1 = pd.read_csv('input2.txt', index_col = ['color', 'status'])
>>> csvFrame1
              item1  item2  item3
color status                     
black up          3      4      6
      down        2      6      7
white up          5      5      5
      down        3      3      2
      left        1      2      1
red   up          2      2      2
      down        1      1      4
      
# Using RegExp to Parse TXT Files : many a times you would end up having an input file the separator oh which is not well 
# defined, in such cases we can define a regex inside read_table to import the data.

Input file :: 
white red blue green 
1        5 2 3 
2 7     8 5 
3 3 6 7

in the above input file the separator is not well defined.

>>> frame5 = pd.read_table('input3.txt',sep='\s+', engine='python')
>>> frame5
   white  red  blue  green
0      1    5     2      3
1      2    7     8      5
2      3    3     6      7

# In this example, we would be extracting the numeric part from a TXT file, in which there is a sequence of characters with 
# numerical values and the literal characters are completely fused.

'''
input :: 
000END123AAA122
001END124BBB321
002END125CCC333
'''

>>> frame5 = pd.read_table('input4.txt',sep='\D+', header = None, engine='python')
>>> frame5
   0    1    2
0  0  123  122
1  1  124  321
2  2  125  333

# if you want to skip some of the lines from an input file while extracting
# If you want to exclude the first five lines, you have to write skiprows = 5, but if you want to rule out the fifth line, 
# you have to write skiprows = [5].

input :: 

This file has been generated by automatic system
white,red,blue,green,animal
12-Feb-2015: Counting of animals inside the house
1,5,2,3,cat
2,7,8,5,dog
13-Feb-2015: Counting of animals outside the house
3,3,6,7,horse
2,2,8,3,duck
4,4,2,1,mouse

>>> pd.read_table('input5.txt',sep=',',skiprows=[0,2,5])
   white  red  blue  green animal
0      1    5     2      3    cat
1      2    7     8      5    dog
2      3    3     6      7  horse
3      2    2     8      3   duck
4      4    4     2      1  mouse

# Thanks to the nrows and skiprows options, you can select the starting line n (n = SkipRows) and the lines to be read after 
# it (nrows = i).

>>> pd.read_csv('input.txt',skiprows=[2],nrows=3,header=None)
   0  1  2  3     4
0  1  5  2  3   cat
1  2  7  8  5   dog
2  2  2  8  3  duck
>>> 
>>> pd.read_csv('input.txt',header=None)
   0  1  2  3      4
0  1  5  2  3    cat
1  2  7  8  5    dog
2  3  3  6  7  horse
3  2  2  8  3   duck
4  4  4  2  1  mouse

# Writing Data in CSV 
>>> frame = pd.DataFrame(np.arange(16).reshape((4,4)),index = ['red', 'blue', 'yellow', 'white'],
                         columns = ['ball', 'pen', 'pencil', 'paper'])

>>> frame
        ball  pen  pencil  paper
red        0    1       2      3
blue       4    5       6      7
yellow     8    9      10     11
white     12   13      14     15

>>> frame.to_csv('output1.csv')

by default the index and column names will also be added to the output file. you can explicitely make sure whether to have it 
in the output file or not.

>>> frame.to_csv('output1.txt', header = None, index = False)

One point to remember when writing files is that NaN values present in a data structure are shown as empty fields in the file.
However, you can replace this empty field with a value to your liking using the na_rep option in the to_csv() function. 
Common values may be NULL, 0, or the same NaN.

>>> frame['paper']['white'] = np.NaN
>>> frame['pen']['red'] = np.NaN

>>> frame
        ball   pen  pencil  paper
red        0   NaN       2    3.0
blue       4   5.0       6    7.0
yellow     8   9.0      10   11.0
white     12  13.0      14    NaN

>>> frame.to_csv('output2.txt', na_rep = 'NULL', header = None, index = None)

# Reading and Writing HTML Files :: conda install html5lib
==============================================================================================================================
Writing Data in HTML ::
>>> frame = pd.DataFrame(np.arange(4).reshape(2,2))
>>> print(frame.to_html())
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>3</td>
    </tr>
  </tbody>
</table>

>>> frame = pd.DataFrame(np.arange(16).reshape(4,4), index = ['A','B','C','D'], columns = ['M1','M2','M3','M4'])
>>> frame
   M1  M2  M3  M4
A   0   1   2   3
B   4   5   6   7
C   8   9  10  11
D  12  13  14  15

writing to a html ::
>>> frame.to_html('output4.html')

Reading Data from an HTML File ::  the read_html() function returns a list of dataframes even if there is only one table.
      
>>> a = pd.read_html('output4.html')
>>> a
[  Unnamed: 0  M1  M2  M3  M4
0          A   0   1   2   3
1          B   4   5   6   7
2          C   8   9  10  11
3          D  12  13  14  15]

>>> a[0]
  Unnamed: 0  M1  M2  M3  M4
0          A   0   1   2   3
1          B   4   5   6   7
2          C   8   9  10  11
3          D  12  13  14  15

>>> a[0]['M1']
0     0
1     4
2     8
3    12
Name: M1, dtype: int64

>>> val = pd.read_html('file:///Users/sankar.biswas/Desktop/AI:ML%20docs/Notebooks/InputFiles/output4.html')
>>> val
[  Unnamed: 0  M1  M2  M3  M4
0          A   0   1   2   3
1          B   4   5   6   7
2          C   8   9  10  11
3          D  12  13  14  15]

# Reading and Writing Data on Microsoft Excel Files
>>> frameExcel = pd.read_excel('input6.xlsx')

>>> frameExcel
   yellow  white  blue  purple
A       1      2     3       4
B       5      6     7       8
C       9     10    11      12

by default it will read "sheet 1" only  

>>> frameExcel = pd.read_excel('input6.xlsx', 'Sheet2')
>>> frameExcel
   Maroon  pink  red  violet
a      11    22   33      44
b      55    66   77      88
c      99     0  111     222

>>> frameExcel = pd.read_excel('input6.xlsx', 0)
>>> frameExcel
   yellow  white  blue  purple
A       1      2     3       4
B       5      6     7       8
C       9     10    11      12

you can either write the sheet name or you can give the index which starts from 0.

# Writing and reading Json Data
>>> frameExcel
   yellow  white  blue  purple
A       1      2     3       4
B       5      6     7       8
C       9     10    11      12

>>> frameExcel.to_json('output5.json')

A very good url where you can visualaize and check your json file ::  http://jsonviewer.stack.hu/
>>> a = pd.read_json('output5.json')
>>> a
   yellow  white  blue  purple
A       1      2     3       4
B       5      6     7       8
C       9     10    11      12

json_normalize(), that is able to convert a dict or a list in a table, so then once you have a table we can easily convert it.

>>> from pandas.io.json import json_normalize

# input ::  
'''
[{"writer": "Mark Ross",
 "nationality": "USA",
 "books": [
         {"title": "XML Cookbook", "price": 23.56},
         {"title": "Python Fundamentals", "price": 50.70},
         {"title": "The NumPy library", "price": 12.30}
] },
{"writer": "Barbara Bracket",
 "nationality": "UK",
 "books": [
         {"title": "Java Enterprise", "price": 28.60},
         {"title": "HTML5", "price": 31.35},
         {"title": "Python for Dummies", "price": 28.00}
] }]
'''

>>> import json
>>> file = open('input5.json', 'r')
>>> text = file.read()

>>> text = json.loads(text)
>>> text
[{'writer': 'Mark Ross', 'nationality': 'USA', 'books': [{'title': 'XML Cookbook', 'price': 23.56}, {'title': 
'Python Fundamentals', 'price': 50.7}, {'title': 'The NumPy library', 'price': 12.3}]}, {'writer': 'Barbara Bracket', 
'nationality': 'UK', 'books': [{'title': 'Java Enterprise', 'price': 28.6}, {'title': 'HTML5', 'price': 31.35}, 
{'title': 'Python for Dummies', 'price': 28.0}]}]

>>> a = json_normalize(text,'books')
>>> a
   price                title
0  23.56         XML Cookbook
1  50.70  Python Fundamentals
2  12.30    The NumPy library
3  28.60      Java Enterprise
4  31.35                HTML5
5  28.00   Python for Dummies

>>> a = json_normalize(text,'books',['nationality','writer'])

>>> a
   price                title nationality           writer
0  23.56         XML Cookbook         USA        Mark Ross
1  50.70  Python Fundamentals         USA        Mark Ross
2  12.30    The NumPy library         USA        Mark Ross
3  28.60      Java Enterprise          UK  Barbara Bracket
4  31.35                HTML5          UK  Barbara Bracket
5  28.00   Python for Dummies          UK  Barbara Bracket

# The Format HDF5
=============================================================================================================================
The HDF term stands for hierarchical data format. When your data analysis involves large amounts of data, it is preferable to 
use them in binary format. HDF5 library handles binary data. HDF5 supports compression in real time. h5py provides a direct 
interface with the high-level APIs HDF5, while PyTables makes abstract many of the details of HDF5 to provide more flexible 
data containers, indexed tables, querying capabilities, and other media on the calculations.
pandas has a class-like dict called HDFStore, using PyTables to store pandas objects

>>> from pandas.io.pytables import HDFStore
Now you’re ready to store the data of a dataframe within an.h5 file. First, create a dataframe ::
>>> frame = pd.DataFrame(np.arange(16).reshape(4,4),index=['white','black','red','blue'],columns=['up','down','right','left'])
>>> frame
       up  down  right  left
white   0     1      2     3
black   4     5      6     7
red     8     9     10    11
blue   12    13     14    15

Now create a file HDF5 calling it mydata.h5, then enter the data inside of the dataframe.
>>> store = HDFStore('myData.h5')
>>> store
<class 'pandas.io.pytables.HDFStore'>
File path: myData.h5

>>> store['obj1'] = frame

Now you can store multiple data structure like this :: 
>>> store['obj2'] = frame

>>> store['obj2']
       up  down  right  left
white   0     1      2     3
black   4     5      6     7
red     8     9     10    11
blue   12    13     14    15

# Pickle—Python Object Serialization ::
The pickle module implements a powerful algorithm for serialization and deserialization of a data structure implemented in 
Python. Pickling is the process in which the hierarchy of an object is converted into a stream of bytes. This allows an object 
to be transmitted and stored, and then to be rebuilt by the receiver itself retaining all the original features.
the picking operation is carried out by the pickle module, but currently there is a module called cPickle which is the result 
of an enormous amount of work optimizing the pickle module (written in C). This module can be in fact in many cases even 
1,000 times faster than the pickle module.

Serialize a Python Object with cPickle ::
>>> import pickle

>>> data = { 'color': ['white','red'], 'value': [5, 7]}      
>>> pickled_data = pickle.dumps(data)

>>> print(pickled_data)
b'\x80\x03}q\x00(X\x05\x00\x00\x00colorq\x01]q\x02(X\x05\x00\x00\x00whiteq\x03X\x03\x00\x00\x00redq\x04eX\x05\x00\x00\x00valueq\x05]q\
x06(K\x05K\x07eu.'

So, it has been serialized. Once you have serialized data, they can easily be written on a file or sent over a socket, pipe, 
etc. After being transmitted, it is possible to reconstruct the serialized object (deserialization) with the loads() function 
of the cPickle module.

>>> nframe = pickle.loads(pickled_data)
>>> nframe
{'color': ['white', 'red'], 'value': [5, 7]}

Pickling and unpickling using Pandas library ::
      
>>> frame = pd.DataFrame(np.arange(16).reshape(4,4), index =['up','down','left','right'])
>>> frame.to_pickle('frame.pkl')

a file named frame.pkl will be created which will have the details of the serialized object.

>>> pd.read_pickle('frame.pkl')
        0   1   2   3
up      0   1   2   3
down    4   5   6   7
left    8   9  10  11
right  12  13  14  15



